# Tuning with LLMs
Tuning with LLMs
Instruction-based fine-tuning, referred to as instruction GPT. It trains the language models to follow specific instructions and generate appropriate responses. For instruction-tuning, the dataset plays an important role as it provides structured examples of instructions, contexts, and responses, allowing the model to learn how to handle various tasks effectively. Instruction GPT often uses human feedback to refine and improve model performance; however, this lab doesn't cover this aspect.

The context and instruction are concatenated to form a single input sequence that the model can understand and use to generate the correct response.

Context and instruction
•	Instruction: A command to specify what the model should do
•	Context: Additional information or background required for performing the instruction
•	Combined input: The instruction and context combine together into a single input sequence
